{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "from itertools import compress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the cell below to true if the data/CDR and data/OHW files ever need refreshing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_refresh = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if file_refresh == True:\n",
    "\n",
    "    # Refreshing CDR files\n",
    "\n",
    "    # running this cell will output to the src folder. The files should be reviewed and moved to the data/CDR folder when done.\n",
    "    search_dict = {\n",
    "        'CDR_01.json':'carbon%20removal',\n",
    "        'CDR_02.json':'carbon%20dioxide%20removal',\n",
    "        'CDR_03.json':'carbon%20sequestration',\n",
    "        'CDR_04.json':'carbon%20dioxide%20sequestration',\n",
    "        'CDR_05.json':'carbon%20capture',\n",
    "        'CDR_06.json':'carbon%20capture%20and%20sequestration',\n",
    "        'CDR_07.json':'carbon%20capture%20and%20storage',\n",
    "        'CDR_08.json':'carbon%20capture%20utilization%20and%20storage',\n",
    "        'CDR_09.json':'CCS',\n",
    "        'CDR_10.json':'CCUS',\n",
    "        'CDR_11.json':'CDR',\n",
    "        'CDR_12.json':'carbon%20mineralization',\n",
    "        'CDR_13.json':'carbon%dioxide%20mineralization',\n",
    "        'CDR_14.json':'carbon%20storage',\n",
    "        'CDR_15.json':'direct%20air%20capture',\n",
    "        'CDR_16.json':'direct%20air%20carbon%20capture',\n",
    "    }\n",
    "\n",
    "    filenames = []\n",
    "    searches = []\n",
    "    for item in search_dict.items():\n",
    "        #print(item)\n",
    "        key, value = item\n",
    "        filename = key\n",
    "        prefix = 'https://api.openalex.org/works?select=id,display_name,authorships,referenced_works,open_access&filter=from_publication_date:2020-01-01,to_publication_date:2023-08-01,fulltext.search:'\n",
    "        insert = value\n",
    "        suffix = '&page={}'\n",
    "        url = prefix + insert + suffix\n",
    "        filenames.append(filename)\n",
    "        searches.append(url)\n",
    "\n",
    "        #used_url = 'https://api.openalex.org/works?select=id,display_name,authorships,referenced_works,open_access&filter=from_publication_date:2020-01-01,to_publication_date:2023-08-01,fulltext.search:carbon%20removal&page={}'\n",
    "        #print(url)\n",
    "\n",
    "    for i in range(len(filenames)):\n",
    "\n",
    "        filename = filenames[i]\n",
    "        use_url = searches[i]\n",
    "\n",
    "        print(\"on filename\", filename)\n",
    "\n",
    "        page = 1\n",
    "        has_more_pages = True\n",
    "        fewer_than_10k_results = True\n",
    "\n",
    "        all_results = []\n",
    "\n",
    "        # loop through pages\n",
    "        while has_more_pages and fewer_than_10k_results:\n",
    "\n",
    "            print(\"on page\", str(page))\n",
    "            \n",
    "            # set page value and request page from OpenAlex\n",
    "            url = use_url.format(page)\n",
    "            #print('\\n' + url)\n",
    "            page_with_results = requests.get(url).json()\n",
    "            \n",
    "            # loop through partial list of results\n",
    "            results = page_with_results['results']\n",
    "            for i,work in enumerate(results):\n",
    "                all_results.append(work)\n",
    "\n",
    "            # next page\n",
    "            page += 1\n",
    "            \n",
    "            # end loop when either there are no more results on the requested page \n",
    "            # or the next request would exceed 10,000 results\n",
    "            per_page = page_with_results['meta']['per_page']\n",
    "            has_more_pages = len(results) == per_page\n",
    "            fewer_than_10k_results = per_page * page <= 10000\n",
    "\n",
    "        with(open(filename, 'w')) as outf:\n",
    "            json.dump(all_results, outf)\n",
    "\n",
    "\n",
    "\n",
    "    # Refreshing OHW files\n",
    "\n",
    "    # running this cell will output to the src folder. The files should be reviewed and moved to the data/CDR folder when done.\n",
    "    OHW_OH_json = json.load(open('/workspaces/OHW_in_CDR/data/OHW/OHW_OH.json'))\n",
    "\n",
    "    search_dict = {\n",
    "        'OHW_OH.json':'open%20hardware',\n",
    "        'OHW_OSH.json':'open%20source%20hardware'\n",
    "    }\n",
    "\n",
    "    filenames = []\n",
    "    searches = []\n",
    "    for item in search_dict.items():\n",
    "        key, value = item\n",
    "        filename = key\n",
    "        prefix = 'https://api.openalex.org/works?select=id,display_name,authorships,referenced_works,open_access&filter=from_publication_date:2020-01-01,to_publication_date:2023-08-01,fulltext.search:'\n",
    "        insert = value\n",
    "        suffix = '&page={}'\n",
    "        url = prefix + insert + suffix\n",
    "        filenames.append(filename)\n",
    "        searches.append(url)\n",
    "\n",
    "    for i in range(len(filenames)):\n",
    "\n",
    "        filename = filenames[i]\n",
    "        use_url = searches[i]\n",
    "        print(\"on filename\", filename)\n",
    "\n",
    "        page = 1\n",
    "        has_more_pages = True\n",
    "        fewer_than_10k_results = True\n",
    "\n",
    "        all_results = []\n",
    "\n",
    "        # loop through pages\n",
    "        while has_more_pages and fewer_than_10k_results:\n",
    "\n",
    "            print(\"on page\", str(page))\n",
    "            \n",
    "            # set page value and request page from OpenAlex\n",
    "            url = use_url.format(page)\n",
    "            #print('\\n' + url)\n",
    "            page_with_results = requests.get(url).json()\n",
    "            \n",
    "            # loop through partial list of results\n",
    "            results = page_with_results['results']\n",
    "            for i,work in enumerate(results):\n",
    "                all_results.append(work)\n",
    "\n",
    "            # next page\n",
    "            page += 1\n",
    "            \n",
    "            # end loop when either there are no more results on the requested page \n",
    "            # or the next request would exceed 10,000 results\n",
    "            per_page = page_with_results['meta']['per_page']\n",
    "            has_more_pages = len(results) == per_page\n",
    "            fewer_than_10k_results = per_page * page <= 10000\n",
    "\n",
    "        with(open(filename, 'w')) as outf:\n",
    "            json.dump(all_results, outf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine files to make dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_nums = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16']\n",
    "all_works = []\n",
    "\n",
    "for i in range(len(file_nums)):\n",
    "\n",
    "    file_num = file_nums[i]\n",
    "    pathstr = '/workspaces/OHW_in_CDR/data/CDR/CDR_' + file_num + '.json'\n",
    "    lst = json.load(open(pathstr))\n",
    "\n",
    "    for r in lst:\n",
    "        works = [r['id'], r['open_access']['is_oa'], r['referenced_works'], r['authorships']]\n",
    "        all_works.append(works)\n",
    "\n",
    "print(len(all_works))\n",
    "\n",
    "df_works_CDR = pd.DataFrame(all_works)\n",
    "df_works_CDR.head()\n",
    "\n",
    "# 11798"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_nums = ['OH', 'OSH']\n",
    "all_ohw_works = []\n",
    "\n",
    "for i in range(len(file_nums)):\n",
    "\n",
    "    file_num = file_nums[i]\n",
    "    pathstr = '/workspaces/OHW_in_CDR/data/OHW/OHW_' + file_num + '.json'\n",
    "    lst = json.load(open(pathstr))\n",
    "\n",
    "    for r in lst:\n",
    "        works = [r['id'], r['open_access']['is_oa'], r['referenced_works'], r['authorships']]\n",
    "        all_ohw_works.append(works)\n",
    "\n",
    "print(len(all_ohw_works))\n",
    "\n",
    "df_works_OHW = pd.DataFrame(all_ohw_works)\n",
    "df_works_OHW.head()\n",
    "\n",
    "# 2351"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate into OA (open access) and NA (non-open access) objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CDR_OA = df_works_CDR.loc[df_works_CDR[1] == True]\n",
    "df_CDR_NA = df_works_CDR.loc[df_works_CDR[1] == False]\n",
    "print(len(df_CDR_OA), len(df_CDR_NA))\n",
    "\n",
    "# 5693 6105\n",
    "\n",
    "df_OHW_OA = df_works_OHW.loc[df_works_OHW[1] == True]\n",
    "df_OHW_NA = df_works_OHW.loc[df_works_OHW[1] == False]\n",
    "print(len(df_OHW_OA), len(df_OHW_NA))\n",
    "\n",
    "# 1215 1136"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open hardware cited in the full text of co-authorsâ€™ works (2nd connection to OHW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is to answer the question of whether open hardware works added value to the work being published by being a work published by one or more co-authors, indicating likely awareness among the authors of open hardware because one of the co-authors has published OHW-related research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author_ids(df):\n",
    "    ids = []\n",
    "    col = df[3]\n",
    "    for r in col:\n",
    "        work_authors = r\n",
    "        for work_author in work_authors:\n",
    "            ids.append(work_author['author']['id'])\n",
    "    return ids\n",
    "\n",
    "def get_author_objects(author_ids):\n",
    "    searches = []\n",
    "    author_objs = []\n",
    "\n",
    "    for id in author_ids:\n",
    "        prefix = 'https://api.openalex.org/authors?filter=ids.openalex:'\n",
    "        insert = id\n",
    "        suffix = '&page={}'\n",
    "        url = prefix + insert + suffix\n",
    "        searches.append(url)\n",
    "\n",
    "    for i in range(len(searches)):\n",
    "        use_url = searches[i]\n",
    "        print(\"on search\", str(i))\n",
    "\n",
    "        page = 1\n",
    "        has_more_pages = True\n",
    "        fewer_than_10k_results = True\n",
    "\n",
    "        # loop through pages\n",
    "        while has_more_pages and fewer_than_10k_results:\n",
    "\n",
    "            #print(\"on page\", str(page))\n",
    "            \n",
    "            # set page value and request page from OpenAlex\n",
    "            url = use_url.format(page)\n",
    "            #print('\\n' + url)\n",
    "            page_with_results = requests.get(url).json()\n",
    "            \n",
    "            # loop through partial list of results\n",
    "            results = page_with_results['results']\n",
    "            for i,author in enumerate(results):\n",
    "                author_objs.append(author)\n",
    "\n",
    "            # next page\n",
    "            page += 1\n",
    "            \n",
    "            # end loop when either there are no more results on the requested page \n",
    "            # or the next request would exceed 10,000 results\n",
    "            per_page = page_with_results['meta']['per_page']\n",
    "            has_more_pages = len(results) == per_page\n",
    "            fewer_than_10k_results = per_page * page <= 10000\n",
    "\n",
    "    return author_objs\n",
    "    \n",
    "def get_citation_metrics(author_ids, author_objs):\n",
    "    saved_summary_stats = []\n",
    "    #print(\"in citation metrics\")\n",
    "    for r in author_objs:\n",
    "        id = r['id']\n",
    "        ss_obj = r['summary_stats']\n",
    "        #print(ss_obj)\n",
    "        summary_stats = [id, ss_obj['2yr_mean_citedness'], ss_obj['h_index'], ss_obj['i10_index']]\n",
    "        #print(summary_stats)\n",
    "        if summary_stats[0] in author_ids:\n",
    "            saved_summary_stats.append(summary_stats)\n",
    "    df_summary_stats = pd.DataFrame(saved_summary_stats)\n",
    "    print(df_summary_stats.head())\n",
    "\n",
    "    return df_summary_stats\n",
    "\n",
    "def get_ref_ids(df):\n",
    "    refs = []\n",
    "    col = df[2]\n",
    "    for r in col:\n",
    "        work_refs = r\n",
    "        for work_ref in work_refs:\n",
    "            refs.append(work_ref)\n",
    "    return refs\n",
    "\n",
    "def get_ids(df):\n",
    "    ids = []\n",
    "    col = df[0]\n",
    "    for r in col:\n",
    "        id = r\n",
    "        ids.append(id)\n",
    "    return ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for assessing author matches\n",
    "cdr_oa_author_ids = get_author_ids(df_CDR_OA)\n",
    "cdr_na_author_ids = get_author_ids(df_CDR_NA)\n",
    "ohw_oa_author_ids = get_author_ids(df_OHW_OA)\n",
    "ohw_na_author_ids = get_author_ids(df_OHW_NA)\n",
    "\n",
    "# for assessing referenced work matches\n",
    "cdr_oa_ref_ids = get_ref_ids(df_CDR_OA)\n",
    "cdr_na_ref_ids = get_ref_ids(df_CDR_NA)\n",
    "ohw_oa_ids = get_ids(df_OHW_OA)\n",
    "ohw_na_ids = get_ids(df_OHW_NA)\n",
    "\n",
    "print(len(all_works), len(all_ohw_works))\n",
    "print(len(cdr_oa_author_ids), len(cdr_na_author_ids))\n",
    "print(len(ohw_oa_author_ids), len(ohw_na_author_ids))\n",
    "print(len(ohw_oa_ids), len(ohw_na_ids))\n",
    "\n",
    "# 11798 2351\n",
    "# 33151 28766\n",
    "# 6695 4741\n",
    "# 1215 1136"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look for matches between the CDR author IDs and the OHW author IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohw_author_ids = []\n",
    "for id in ohw_oa_author_ids:\n",
    "    ohw_author_ids.append(id)\n",
    "for id in ohw_na_author_ids:\n",
    "    ohw_author_ids.append(id)\n",
    "\n",
    "cdr_ohw_oa_author_matches = (el in cdr_oa_author_ids for el in ohw_author_ids)\n",
    "cdr_ohw_na_author_matches = (el in cdr_na_author_ids for el in ohw_author_ids)\n",
    "\n",
    "cdr_ohw_oa_author_match_count = sum(cdr_ohw_oa_author_matches)\n",
    "cdr_ohw_na_author_match_count = sum(cdr_ohw_na_author_matches)\n",
    "print(cdr_ohw_oa_author_match_count, cdr_ohw_na_author_match_count)\n",
    "\n",
    "# 1027 720, 16.7 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For those matches, get the author ID to see later how their metrics performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdr_ohw_oa_author_matches = [el in cdr_oa_author_ids for el in ohw_author_ids]\n",
    "match_idxs = list(compress(range(len(cdr_ohw_oa_author_matches)), cdr_ohw_oa_author_matches))\n",
    "cdr_ohw_oa_match_author_ids = [cdr_oa_author_ids[i] for i in match_idxs]\n",
    "print(cdr_ohw_oa_match_author_ids)\n",
    "\n",
    "cdr_ohw_na_author_matches = [el in cdr_na_author_ids for el in ohw_author_ids]\n",
    "match_idxs = list(compress(range(len(cdr_ohw_na_author_matches)), cdr_ohw_na_author_matches))\n",
    "cdr_ohw_na_match_author_ids = [cdr_na_author_ids[i] for i in match_idxs]\n",
    "print(cdr_ohw_na_match_author_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdr_ohw_oa_author_nonmatches = [not el in cdr_oa_author_ids for el in ohw_author_ids]\n",
    "match_idxs = list(compress(range(len(cdr_ohw_oa_author_nonmatches)), cdr_ohw_oa_author_nonmatches))\n",
    "cdr_ohw_oa_nonmatch_author_ids = [cdr_oa_author_ids[i] for i in match_idxs]\n",
    "print(cdr_ohw_oa_nonmatch_author_ids)\n",
    "\n",
    "cdr_ohw_na_author_nonmatches = [not el in cdr_na_author_ids for el in ohw_author_ids]\n",
    "match_idxs = list(compress(range(len(cdr_ohw_na_author_nonmatches)), cdr_ohw_na_author_nonmatches))\n",
    "cdr_ohw_na_nonmatch_author_ids = [cdr_na_author_ids[i] for i in match_idxs]\n",
    "print(cdr_ohw_na_nonmatch_author_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for assessing whether OHW is helpful for citation metrics\n",
    "# each call returns a tuple of (ids, impact_factors, h_indices, i10_indices)\n",
    "cdr_ohw_oa_nonmatch_author_ids_trunc = cdr_ohw_oa_nonmatch_author_ids[0:len(cdr_ohw_oa_match_author_ids)]\n",
    "cdr_ohw_na_nonmatch_author_ids_trunc = cdr_ohw_na_nonmatch_author_ids[0:len(cdr_ohw_na_match_author_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdr_ohw_oa_author_objs = get_author_objects(cdr_ohw_oa_match_author_ids)\n",
    "cdr_ohw_na_author_objs = get_author_objects(cdr_ohw_na_match_author_ids)\n",
    "# 7 m 8.9 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdr_nohw_oa_author_objs = get_author_objects(cdr_ohw_oa_nonmatch_author_ids_trunc)\n",
    "cdr_nohw_na_author_objs = get_author_objects(cdr_ohw_na_nonmatch_author_ids_trunc)\n",
    "# 7 m 8.7 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdr_ohw_oa_metrics = get_citation_metrics(cdr_ohw_oa_match_author_ids, cdr_ohw_oa_author_objs)\n",
    "cdr_ohw_na_metrics = get_citation_metrics(cdr_ohw_na_match_author_ids, cdr_ohw_na_author_objs)\n",
    "cdr_nohw_oa_metrics = get_citation_metrics(cdr_ohw_oa_nonmatch_author_ids, cdr_nohw_oa_author_objs)\n",
    "cdr_nohw_na_metrics = get_citation_metrics(cdr_ohw_na_nonmatch_author_ids, cdr_nohw_na_author_objs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ohw_oa_metrics = get_citation_metrics2(ohw_oa_author_ids, get_author_objects(ohw_oa_author_ids))\n",
    "#ohw_na_metrics = get_citation_metrics2(ohw_na_author_ids, get_author_objects(ohw_na_author_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get averages for citation metrics for each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impact Factors\n",
    "avg_if_ohw_oa = cdr_ohw_oa_metrics[1].mean()\n",
    "avg_if_ohw_na = cdr_ohw_na_metrics[1].mean()\n",
    "avg_if_nohw_oa = cdr_nohw_oa_metrics[1].mean()\n",
    "avg_if_nohw_na = cdr_nohw_na_metrics[1].mean()\n",
    "\n",
    "# H-Indices\n",
    "avg_h_ohw_oa = cdr_ohw_oa_metrics[2].mean()\n",
    "avg_h_ohw_na = cdr_ohw_na_metrics[2].mean()\n",
    "avg_h_nohw_oa = cdr_nohw_oa_metrics[2].mean()\n",
    "avg_h_nohw_na = cdr_nohw_na_metrics[2].mean()\n",
    "\n",
    "# I10-Indices\n",
    "avg_i10_ohw_oa = cdr_ohw_oa_metrics[3].mean()\n",
    "avg_i10_ohw_na = cdr_ohw_na_metrics[3].mean()\n",
    "avg_i10_nohw_oa = cdr_nohw_oa_metrics[3].mean()\n",
    "avg_i10_nohw_na = cdr_nohw_na_metrics[3].mean()\n",
    "\n",
    "# Print results\n",
    "print(\"IF\", avg_if_ohw_oa, avg_if_ohw_na, avg_if_nohw_oa, avg_if_nohw_na)\n",
    "print(\"H\", avg_h_ohw_oa, avg_h_ohw_na, avg_h_nohw_oa, avg_h_nohw_na)\n",
    "print(\"I10\", avg_i10_ohw_oa, avg_i10_ohw_na, avg_i10_nohw_oa, avg_i10_nohw_na)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open hardware cited in the title or abstract of the referenced works (3rd connection to OHW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is to answer the question of whether one or more open hardware works added value to the work being published by being included as a referenced work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohw_ids = []\n",
    "for id in ohw_oa_ids:\n",
    "    ohw_ids.append(id)\n",
    "for id in ohw_na_ids:\n",
    "    ohw_ids.append(id)\n",
    "\n",
    "cdr_ohw_oa_ref_match_count = sum(el in cdr_oa_ref_ids for el in ohw_ids)\n",
    "cdr_ohw_na_ref_match_count = sum(el in cdr_na_ref_ids for el in ohw_ids)\n",
    "print(cdr_ohw_oa_ref_match_count, cdr_ohw_na_ref_match_count)\n",
    "\n",
    "# 9341 6183 14 minutes\n",
    "# 14 4 26.4 s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
